# MFA-YOLO
MFA-YOLO: A Multi-Scale Fusion and Attention Mechanism Enhanced YOLOv8 for Small Object Detection in Remote Sensing Images
# Abstract
Detecting small objects in remote sensing images remains a significant challenge due totheir inherently low pixel proportion and limited feature representation, which is furthercomplicated by diverse scenes and complex backgrounds. To address this, we proposeMFA-YOLO, an enhanced object detection model based on YOLOv8s. In the backbonenetwork, we introduce the Cross-stage Fusion Enhanced Module with EfficientMulti-scale Feature Aggregation (CFEMA), which preserves richer contextualinformation from shallow features, thereby strengthening feature extraction capabilitywhile maintaining low computational cost. Innovatively, we also design aContext-Guided Attention-based Feature Pyramid Network (CGA-FPN) as the necknetwork. This module integrates backbone features into the neck output via a SpatialDynamic Fusion Module (SDFM) that utilizes attention mechanisms to generateadaptive fusion weights, dynamically adjusting the contribution of different inputfeatures and thus achieving effective feature calibration and optimization. Furthermore.we adopt the Wise-GIoU loss function, which combines the minimum enclosing rectangleof GIoU with the non-monotonic focusing mechanism of Wise-IoU v3. This formulationsupplies meaningful gradient signals even for non-overlapping boxes and dynamicallymodulates gradients based on sample quality, thereby improving localization accuracyfor small objects. Experiments on the NWPU VHR-10, RSOD, VEDAl, CODrone, andVisDrone datasets show that, compared to the baseline YOLOv8, MFA-YOLO achievesimprovements in mAP@0.5 of 6.2%, 4.6%, 8.3%, 2.4%, and 6.2%, respectively.Moreover, it yields significant gains in the mAP-Small metric, improving by 15.0% onNWPU VHR-10 and 5.0% on VEDAI. These results collectively validate the strongcapability of the proposed model in detecting small objects in remote sensing imagery.
